<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech Recognition</title>
    <script src="https://cdn.socket.io/4.0.0/socket.io.min.js"></script>
</head>
<body>
    <h1>Live Transcription</h1>
    
    <label for="language_id">Select Language:</label>
    <select id="language_id">
        <option value="Apatani">Apatani</option>
        <option value="Bhutanese">Bhutanese</option>
        <option value="French">French</option>
        <option value="Hindi">Hindi</option>
        <option value="Monpa">Monpa</option>
    </select>
    <button id="start-button">Start Transcription</button>

    <p id="transcription">No transcription yet...</p>
    <audio id="audioPlayer" controls></audio>

    <script>
        const socket = io(window.location.origin, {
            transports: ['websocket'],
            upgrade: false
        });

        const startButton = document.getElementById('start-button');
        const languageSelect = document.getElementById('language_id');
        const transcriptionDiv = document.getElementById('transcription');

        // Set buffer size (in samples)
        const BUFFER_SIZE = 2048; // You can adjust this value

        function selectLanguage(languageId) {
            fetch('/select_language', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/x-www-form-urlencoded'
                },
                body: `language_id=${languageId}`
            })
            .then(response => response.json())
            .then(data => {
                if (data.status === 'success') {
                    console.log('Language updated successfully');
                } else {
                    console.log('Error updating language');
                }
            })
            .catch(error => console.error('Error:', error));
        }

        const audioWorkletCode = `
            class AudioProcessor extends AudioWorkletProcessor {
                constructor() {
                    super();
                    this.bufferSize = ${BUFFER_SIZE};
                    this.buffer = new Float32Array(this.bufferSize);
                    this.bufferIndex = 0;
                }

                process(inputs, outputs, parameters) {
                    const input = inputs[0];
                    if (input.length > 0) {
                        const inputChannel = input[0];
                        for (let i = 0; i < inputChannel.length; i++) {
                            this.buffer[this.bufferIndex] = inputChannel[i];
                            this.bufferIndex++;

                            if (this.bufferIndex >= this.bufferSize) {
                                const int16Data = this.convertFloat32ToInt16(this.buffer);
                                this.port.postMessage(int16Data.buffer, [int16Data.buffer]);
                                this.bufferIndex = 0;
                            }
                        }
                    }
                    return true;
                }
                
                convertFloat32ToInt16(buffer) {
                    const int16Buffer = new Int16Array(buffer.length);
                    for (let i = 0; i < buffer.length; i++) {
                        const s = Math.max(-1, Math.min(1, buffer[i]));
                        int16Buffer[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }
                    return int16Buffer;
                }
            }

            registerProcessor('audio-processor', AudioProcessor);
        `;

        startButton.addEventListener('click', async function() {
            const languageId = languageSelect.value;
            selectLanguage(languageId);

            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: { sampleRate: 16000, channelCount: 1 } });
                const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                
                const blob = new Blob([audioWorkletCode], { type: 'application/javascript' });
                const workletUrl = URL.createObjectURL(blob);

                await audioContext.audioWorklet.addModule(workletUrl);
                
                const source = audioContext.createMediaStreamSource(stream);
                const audioWorkletNode = new AudioWorkletNode(audioContext, 'audio-processor', {
                    outputChannelCount: [1],
                    processorOptions: {
                        bufferSize: BUFFER_SIZE
                    }
                });
                
                audioWorkletNode.port.onmessage = (event) => {
                    socket.emit('audio_stream', event.data);
                };
                
                source.connect(audioWorkletNode);
                audioWorkletNode.connect(audioContext.destination);

                console.log('Audio processing started with buffer size:', BUFFER_SIZE);
            } catch (err) {
                console.error('Error accessing microphone: ', err);
            }
        });

        socket.on('connect', () => {
            console.log('Connected to server');
        });

        socket.on('disconnect', () => {
            console.log('Disconnected from server');
        });

        socket.on('transcription', function(data) {
            console.log('Received transcription:', data.transcription);
            transcriptionDiv.innerText = data.transcription;
        });

        socket.on('connect_error', (error) => {
            console.error('Connection error:', error);
        });
    </script>
</body>
</html>